# Results

## Models can be aligned and compared within and between years

We examined the change in how tokens are used in biomedical text over time.
Our evaluation of token usage was derived from machine learning models that were designed to predict, given a portion of a string of words, the most likely actual string of words.
In these models, each token was represented as a vector in coordinate space.
However, model training was stochastic and the coordinate space was arbitrary within models.

![
A. Without alignment, each word2vec model has its own coordinate space.
This is a UMAP visualization of 5000 randomly sampled tokens from 5 distinct Word2Vec models trained on the text published in the year 2010.
Each data point represents a token, and the color represents the respective Word2Vec model.
B. The highlighted token 'probiotics' shows up in its respective clusters.
Each data point represents a token, and the color represents the Word2Vec model.
C. After the alignment step, the token 'probiotic' is closer in vector space.
Each data point represents a token, and the color represents the different Word2Vec models.
](https://raw.githubusercontent.com/danich1/biovectors/54d54854725adf8cec788e26c0411af35f105e8e/figure_generation/output/Figure_1.png){#fig:word2vec_alignment width="100%"}
<!--this figure lacks a systematic comparison - could you prepare a plot comparing, with and without alignment, intra and inter-model distances for: 1) a randomly selected set of tokens with the same token; 2) the same randomly selected set of tokens with their 5 closest neighbors (one neighbor set for each model - use the union across models; 3) the same randomly selected set of tokens but inter-token distances-->

<!--has orthogonal Procrustes been used this way before?-->
Model alignment is an essential step in allowing word2vec models to be compared.
We visualized this process using the year 2010 as an example.
Before alignment, each Word2Vec model has its own unique coordinate space (Figure {@fig:word2vec_alignment}A).
This point is reinforced by the token 'probiotic', where it appears in its respective cluster (Figure {@fig:word2vec_alignment}B).
This result highlights that models cannot be directly compared without an alignment step.
After performing model alignment, we can see that each model is projected onto the same coordinate space (Figure {@fig:word2vec_alignment}C).
The 'probiotic' tokens are now closer, signifying that they can now be directly compared (Figure {@fig:word2vec_alignment}C); however, there is still an issue of variation that needs to be corrected.

Our goal was to understand changes in token usage, but this analysis was performed against the backdrop of rapid changes in publishing practices.
The texts available for our analysis were open access manuscripts available through PubMed Central.
The growth in the amount of available text and the uneven nature of adoption of open access publishing during the interval studied was expected to induce changes in the underlying machine learning models, making comparisons more difficult.
We aimed to correct for this change in the underlying models by developing a statistic that, instead of using pairwise comparisons of token distances between individual models, integrated multiple models for each year by comparing tokens' intra- and inter-year variabilities.
<!--brief description of metric here-->

![
A. Tokens appear to have a greater difference if a correction step is not implemented.
This line plot shows the percent difference of the average of all tokens shared across the years relative to 2010-2011.
The orange line represents tokens without considering variation, while the green line shows the variation correction step.
B. Change points can still be detected after accounting for variation.
This line plot shows the percent difference of tokens expected to have a changepoint compared to our variation correction model.
The line in purple and orange represents the 'cas9' token and the 'pandemic' token, respectively, while the green line is our variation correction model.
](https://raw.githubusercontent.com/danich1/biovectors/54d54854725adf8cec788e26c0411af35f105e8e/figure_generation/output/Figure_2.png){#fig:novel_distance_validation width="100%"}

We expect most tokens to change little from year-to-year; substantial changes likely suggest model drift as opposed to true linguistic change.
We selected all tokens that appeared in each year and compared their similarity with the midpoint year, 2010, using the single-model and integrated-models strategies. <!--why are two years listed in the figure instead of 1? shouldn't there be a self-self comparison?-->
We found that without correction, tokens exhibited systematic change but correcting for changes in model variability stabilized inter-year distances (Figure {@fig:novel_distance_validation}A).
We next sought to verify that the correction strategy did not eliminate change for words with changing usage.
We selected 'pandemic' and 'cas9' as exemplar tokens, expecting the COVID19 pandemic and CRISPR/cas technologies to have changed the way these tokens were used during the studied interval of 2000-2021.
We found that, even with the correction, these tokens still exhibited substantial changes and that the changes aligned with when we expected usage to be the most in flux (Figure {@fig:novel_distance_validation}B).
<!--this cas9 result is very confusing - why is it different from 2010, but then by 2020 it looks the same as it did in 2010?-->
Based on these results, we used the integrated-model strategy to calculate inter-year token distances for the remainder of this work.

## Terms exhibit detectable changes in usage

![
Preprints and published works share a modest number of detected changepoints.
This Venn diagram shows the number of detected changepoints between preprints (green) and published papers (orange), while yellow represents the number of changepoints shared.
](https://raw.githubusercontent.com/danich1/biovectors/54d54854725adf8cec788e26c0411af35f105e8e/figure_generation/output/Figure_3.png){#fig:preprint_published_changepoints width="100%"}

We next sought to identify tokens that changed during the 2000-2021 interval for text from PubMed Central's Open Access Corpus (PMCOA) and the 20XX-2021 interval for our preprint corpus.
We performed change point detection using METHOD with distances calculated with the integrated-model approach to correct for systematic changes in the underlying corpora.
We found 41281 terms with change points from PMCOA and 2266 from preprints, and the vast majority (##) had a single change-point.
Sentence about new figure (Figure {@fig:preprint_published_changepoints}A).<!--new figure panels A and B showing number of change points per year with each corpus - if presented as a timeline maybe you could put the "most changed" underneath.-->
An example change point was detected for 'cas9' from 2012 to 2013 (Figure {@fig:preprint_published_changepoints}C).<!--make figure panel for this change point - probably showing the change point statistic & arrows with most similar terms in 2012 and 2013-->
Before the change point, its closest neighbors were related genetic elements (e.g., 'cas'1-3).
After the change point, its closest neighbors became terms related to targeting, sgRNA and gRNA, as well as other genome editing strategies, 'talen' and 'zfns'.
The full set of detected change points are available for further analysis (see Data Availability and Software).

For some terms, multiple change points were detected either within or between corpora.
Of the change points detected, 200 were shared between the two corpora.<!--I don't think this is correct - maybe 200 terms _with changepoints_ were shared? cavefish has change points in both but the years are different.-->
We examined the overlap of detected change points between preprints and published articles.
We found a decent number of tokens were related to the COVID-19 (Supplementary Table {@tbl:published_preprint_change_table}).
Plus, we also found that several shared tokens were terms related to experiments that involve animals or wet-lab work (Supplementary Table {@tbl:published_preprint_change_table}). <!--revisit with the updated table -->
Certain terms exhibited multiple change-points in PMCOA.
For example, change points were detected for SARS from both 2002 to 2003 and 2019 to 2020 (Figure {@fig:preprint_published_changepoints}C), consistent with the emergences of SARS-CoV [ref] and SARS-CoV-2 [ref] as observed human pathogens.


## The word-lapse application is an online resource for manual examination biomedical tokens

![
A. The trajectory visualization of the token 'pandemic' through time.
It starts at the first mention of the token and progresses through each subsequent year.
Every datapoint shows the top five neighbors for the respective token.
B. The usage frequency of the token 'pandemic' through time.
The x-axis shows the year, and the y-axis shows the frequency for each token.
C. A word cloud visualization for the top 25 neighbors for the token 'pandemic' each year.
This visualization highlights each neighbor from a particular year and allows for the comparison between two years.
Tokens in purple are shared within both years, while tokens in red or blue are unique to their respective year.
](images/Figure_4.png){#fig:website_walkthrough width="100%"}

We constructed an online application that allows users to examine how tokens change through time.
The application supports token input as text strings or as MeSH IDs, Entrez Gene IDs, and Taxonomy IDs.
Users might elect to explore the term 'pandemic', for which we detected a change point between 2019 and 2020.
Users can examine the token's nearest neighbors through time (Figure {@fig:website_walkthrough}A).
For example, for 'pandemic' users can observe that the token 'epidemic' remains similar through time, but that txid114727 (the H1N1 subtype of influenza) only enters the nearest neighbors with the swine flu pandemic in 2009 and that MeSH:C000657245 (COVID-19) appears in 2020.
The application also shows a frequency chart depicting how often the particular token is used each year (Figure {@fig:website_walkthrough}B), which can be displayed as a raw count or adjusted by the total size of the corpus.
When change points are detected they are indicated on this panel (Figure {@fig:website_walkthrough}B).
The final visualization shows the union of the nearest 25 neighbors from each year ordered by the number years in which they were in the set (Figure {@fig:website_walkthrough}C).
This visualization has a comparison functionality that allows users to examine differences between years.
All functionalities are fully supported across the PMCOA and preprint corpora, and users can toggle between the two.
