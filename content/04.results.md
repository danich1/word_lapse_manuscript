# Results

## Models can be aligned and compared within and between years

We examined how the usage of tokens in biomedical text changes over time.
Our evaluation was derived from machine learning models designed to predict the actual token given a portion of its surrounding tokens.
Each token was represented as a vector in a coordinate space constructed by these models.
However, training these models is stochastic, which results in arbitrary coordinate spaces.

![
A. Without alignment, each word2vec model has its own coordinate space.
This is a UMAP visualization of 5000 randomly sampled tokens from 5 distinct Word2Vec models trained on the text published in 2010.
Each data point represents a token, and the color represents the respective Word2Vec model.
B. The highlighted token 'probiotics' shows up in its respective clusters.
Each data point represents a token, and the color represents the Word2Vec model.
C. After the alignment step, the token 'probiotic' is closer in vector space.
Each data point represents a token, and the color represents the different Word2Vec models.
D. Token distances appear to be vastly different without alignment than with alignment.
This boxplot shows the average distance of 100 randomly sampled tokens shared in every year from 2000 to 2021.
The x-axis shows the various groups being compared (tokens against themselves via intra-year and inter-year distances and tokens against their corresponding neighbors.
The y axis shows the averaged distance for every year.
](https://raw.githubusercontent.com/danich1/biovectors/810e12977d05d90d8d08e5fb34157c3e93f2cb6a/figure_generation/output/Figure_1.png){#fig:word2vec_alignment width="100%"}

Model alignment is an essential step in allowing word2vec models to be compared [@doi:10.48550/arXiv.1605.09096; @doi:10.1038/s41597-021-01047-x].
We visualized this process using the year 2010 as an example.
Before alignment, each model has its own unique coordinate space (Figures {@fig:word2vec_alignment}A and Figure {@fig:word2vec_alignment}B).
This result highlights that models cannot be directly compared without a form of correction.
Post alignment, we see that every model has been projected onto a shared coordinate space (Figure {@fig:word2vec_alignment}C).
We performed a validation experiment to observe token distances pre and post-alignment directly.
As expected, tokens directly compared with themselves, minus alignment, appear to be vastly different than their similar neighbors (Figure {@fig:word2vec_alignment}D).

Our goal was to understand changes in token usage, but this analysis was performed against the backdrop of rapid changes in publishing practices.
The texts available for our analysis were open access manuscripts available through PubMed Central.
The growth in the amount of available text and the uneven adoption of open access publishing during the interval studied was expected to induce changes in the underlying machine learning models, making comparisons more difficult.
We aimed to correct for this change in the underlying models by developing a statistic that, instead of using pairwise comparisons of token distances between individual models, integrated multiple models for each year by comparing tokens' intra- and inter-year variabilities.
This statistic is defined as the ratio of the average distance between two years over the sum of the average distance within each year respectively.

![
A. Tokens appear to have a greater difference if a correction step is not implemented.
This line plot shows the percent difference of the average of all tokens shared across the years relative to 2010-2011.
The orange line represents tokens without considering variation, while the green line shows the variation correction step.
B. Change points can still be detected after accounting for variation.
This line plot shows the percent difference of tokens expected to have a changepoint compared to our variation correction model.
The line in purple and orange represents the 'cas9' token and the 'pandemic' token, respectively, while the green line is our variation correction model.
](https://raw.githubusercontent.com/danich1/biovectors/54d54854725adf8cec788e26c0411af35f105e8e/figure_generation/output/Figure_2.png){#fig:novel_distance_validation width="100%"}

We expect most tokens to change little from year-to-year; substantial changes likely suggest model drift as opposed to true linguistic change.
We selected all tokens that appeared in each year and compared their similarity with the midpoint year, 2010, using the single-model and integrated-models strategies. <!--why are two years listed in the figure instead of 1? shouldn't there be a self-self comparison?-->
We found that without correction, tokens exhibited systematic change but correcting for changes in model variability stabilized inter-year distances (Figure {@fig:novel_distance_validation}A).
We next sought to verify that the correction strategy did not eliminate change for words with changing usage.
We selected 'pandemic' and 'cas9' as exemplar tokens, expecting the COVID19 pandemic and CRISPR/cas technologies to have changed the way these tokens were used during the studied interval of 2000-2021.
We found that, even with the correction, these tokens still exhibited substantial changes and that the changes aligned with when we expected usage to be the most in flux (Figure {@fig:novel_distance_validation}B).
<!--this cas9 result is very confusing - why is it different from 2010, but then by 2020 it looks the same as it did in 2010?-->
Based on these results, we used the integrated-model strategy to calculate inter-year token distances for the remainder of this work.

## Terms exhibit detectable changes in usage

![
A. The number of changepoints increases over time in PMCOA.
The x-axis shows the various time periods, while the y-axis depicts the number of detected changepoints.
B. Regarding preprints, the greatest number of changepoints was during 2018-2019.
The x-axis shows the various time periods, while the y-axis depicts the number of detected changepoints.
C. The token 'cas9' was detected to have a changepoint at 2012-2013.
The x-axis shows the time period since the first appearance of the token, and the y-axis shows the change metric.
D. 'sars' has two detected changepoints within the PMCOA corpus.
The x-axis shows the time period since the first appearance of the token, and the y-axis shows the change metric.
](https://raw.githubusercontent.com/danich1/biovectors/810e12977d05d90d8d08e5fb34157c3e93f2cb6a/figure_generation/output/Figure_3.png){#fig:preprint_published_changepoints width="100%"}

We next sought to identify tokens that changed during the 2000-2021 interval for the text from PubMed Central's Open Access Corpus (PMCOA) and the 2015-2022 interval for our preprint corpus.
We performed change point detection using the CUSUM algorithm with distances calculated with the integrated-model approach to correct for systematic differences in the underlying corpora.
We found 41281 terms with a detected changepoint from PMCOA and 2266 terms from preprints, and the vast majority (38019 for PMCOA and 2260 for preprints) had just a single change-point.
We found that 2020-2021 had the highest number of changepoints for the PMCOA corpus, while 2018-2019 had the highest number of changepoints using preprints (Figures {@fig:preprint_published_changepoints}A and {@fig:preprint_published_changepoints}B).
An example change point was detected for 'cas9' from 2012 to 2013 (Figure {@fig:preprint_published_changepoints}C).
Before the change point, its closest neighbors were related genetic elements (e.g., 'cas'1-3).
After the change point, its closest neighbors became terms related to targeting, sgRNA, and gRNA, as well as other genome editing strategies, 'talen' and 'zfns' (Table {@tbl:cas9_neighbor_table}).
The complete set of detected change points is available for further analysis (see Data Availability and Software).

For some terms, multiple change points were detected within or between corpora.
Out of all change points, 200 were seen by both corpora, while only 25 of the 200 terms shared the same time period.
We examined the overlap of detected change points between preprints and published articles.
We found a decent number of tokens were related to the COVID-19 (Supplementary Table {@tbl:published_preprint_change_table}).
We also found that several shared tokens were related to experiments involving animals or wet-lab work (Supplementary Table {@tbl:published_preprint_change_table}). <!--revisit with the updated table -->
Specific terms exhibited multiple change-points in PMCOA.
For example, change points were detected for SARS from both 2002 to 2003 and 2019 to 2020 (Figure {@fig:preprint_published_changepoints} D), consistent with the emergences of SARS-CoV [@doi:10.1046/j.1440-1843.2003.00517.x] and SARS-CoV-2 [@doi:10.1016/j.ijantimicag.2020.105924; @doi:10.1038/s41564-020-0695-z] as observed human pathogens.


|2012    |2013        |
|--------|------------|
|cas2    |sgrna       |
|crispr1 |talen       |
|cas3    |spcas9      |
|cas1    |zfns        |
|cas10   |grna        |
|crispr3 |zfn         |
|tracrrna|dcas9       |
|crispr  |nickase     |
|csn1    |pcocas9     |
|crispr4 |crispr      |
|cas7    |sgrnas      |
|cas6e   |meganuclease|
|cas4    |tracrrna    |
|cse1    |crispri     |
|cas6    |crrna       |

Table: The fifteen most similar neighbors to the token 'cas9' for the years 2012 and 2013. {#tbl:cas9_neighbor_table}


## The word-lapse application is an online resource for manual examination of biomedical tokens

![
A. The trajectory visualization of the token 'pandemic' through time.
It starts at the first mention of the token and progresses through each subsequent year.
Every data point shows the top five neighbors for the respective token.
B. The usage frequency of the token 'pandemic' through time.
The x-axis shows the year, and the y-axis shows the frequency for each token.
C. A word cloud visualization for the top 25 neighbors for the token 'pandemic' each year.
This visualization highlights each neighbor from a particular year and allows for the comparison between two years.
Tokens in purple are shared within both years, while tokens in red or blue are unique to their respective year.
](images/Figure_4.png){#fig:website_walkthrough width="100%"}

We constructed an online application that allows users to examine how tokens change through time.
The application supports token input as text strings or as MeSH IDs, Entrez Gene IDs, and Taxonomy IDs.
Users might elect to explore the term 'pandemic', for which we detected a change point between 2019 and 2020.
Users can examine the token's nearest neighbors through time (Figure {@fig:website_walkthrough}A).
For example, for 'pandemic' users can observe that the token 'epidemic' remains similar through time, but taxid:114727 (the H1N1 subtype of influenza) only enters the nearest neighbors with the swine flu pandemic in 2009 and that MeSH:C000657245 (COVID-19) appears in 2020.
The application also shows a frequency chart depicting how often the particular token is used each year (Figure {@fig:website_walkthrough}B), which can be displayed as a raw count or adjusted by the total size of the corpus.
When change points are detected, they are indicated on this panel (Figure {@fig:website_walkthrough}B).
The final visualization shows the union of the nearest 25 neighbors from each year ordered by the number of years that neighbor was present (Figure {@fig:website_walkthrough}C).
This visualization has a comparison function that allows users to examine differences between years.
All functionalities are fully supported across the PMCOA and preprint corpora, and users can toggle between the two.
