# Results

## Visualization of Word2Vec Alignment

![
A. Without alignment, each word2vec model has its own coordinate space.
This is a UMAP visualization of 5000 randomly sampled tokens from 5 distinct Word2Vec models trained on the text published in the year 2010.
Each data point represents a token, and the color represents the respective Word2Vec model.
B. The highlighted token 'probiotics' shows up in its respective clusters.
Each data point represents a token, and the color represents the Word2Vec model.
C. After the alignment step, the token 'probiotic' is closer in vector space.
Each data point represents a token, and the color represents the different Word2Vec models.
](https://raw.githubusercontent.com/danich1/biovectors/54d54854725adf8cec788e26c0411af35f105e8e/figure_generation/output/Figure_1.png){#fig:word2vec_alignment width="100%"}

Model alignment is an essential step in allowing word2vec models to be compared.
We visualized this process using the year 2010 as an example.
Before alignment, each Word2Vec model has its own unique coordinate space (Figure {@fig:word2vec_alignment}A).
This point is reinforced by the token 'probiotic', where it appears in its respective cluster (Figure {@fig:word2vec_alignment}B).
This result highlights that models cannot be directly compared without an alignment step.
After performing model alignment, we can see that each model is projected onto the same coordinate space (Figure {@fig:word2vec_alignment}C).
The 'probiotic' tokens are now closer, signifying that they can now be directly compared (Figure {@fig:word2vec_alignment}C); however, there is still an issue of variation that needs to be corrected.

## Confirmation of the new distance metric accounting for inter-year and intra-year variation.

![
A. Tokens appear to have a greater difference if a correction step is not implemented.
This line plot shows the percent difference of the average of all tokens shared across the years relative to 2010-2011.
The orange line represents tokens without considering variation, while the green line shows the variation correction step.
B. Changepoints can still be detected after accounting for variation.
This line plot shows the percent difference of tokens expected to have a changepoint compared to our variation correction model.
The line in purple and orange represents the 'cas9' token and the 'pandemic' token, respectively, while the green line is our variation correction model.
](https://raw.githubusercontent.com/danich1/biovectors/54d54854725adf8cec788e26c0411af35f105e8e/figure_generation/output/Figure_2.png){#fig:novel_distance_validation width="100%"}

Tokens would appear vastly different if intra-year and inter-year variations were not considered.
We compared a single Word2Vec model with our variation correction approach to examine the differences.
The percent difference sharply increases for the single model as it moves further away from 2010-2011 (Figure {@fig: novel_distance_validation} A).
Similarly, our correction method increases as it moves away from 2010-2011; however, it is upper bounded to be no greater than 0.1 (Figure {@fig: novel_distance_validation}A).
This observation suggests that using a single model could result in a higher number of tokens appearing to be different when that is not the case.
Tokens such as 'pandemic' and 'cas9' still have a percent difference of over 100% (Figure {@fig: novel_distance_validation}B).
This suggests that we can detect tokens that are expected to have a changepoint despite our correction method.

## Examining detected changepoints between preprints and published papers

![
Preprints and published works share a modest number of detected changepoints.
This Venn diagram shows the number of detected changepoints between preprints (green) and published papers (orange), while yellow represents the number of changepoints shared.
](https://raw.githubusercontent.com/danich1/biovectors/54d54854725adf8cec788e26c0411af35f105e8e/figure_generation/output/Figure_3.png){#fig:preprint_published_changepoints width="100%"}

Our approach detected a substantial amount of changepoints across preprints and published papers (Figure {@fig:preprint_published_changepoints}).
We found that 'cas9' was detected to have a changepoint from 2012 to 2013.
Upon closer examination, the top ten neighbors for this token included 'talens', 'zfns', and 'nickase', which are concepts related to gene-editing (Supplementary Table {@tbl:cas9_table}), suggesting that this 'cas9' developed an association for gene-editing during that time period.
Similarly, we found that 'pandemic' had a changepoint between 2019 and 2020.
Looking at the top ten neighbors for 'pandemic' this token we see concpets  such as 'lockdown', 'coronavirus (mesh_c000657245)', and 'surge' (Supplementary Table {@tbl:pandemic_table}).
These concepts suggest that 'pandemic' picked up an association with the coronavirus (COVID-19) outbreak. 
We made our listing available for all detected changepoints (see Data Availability section).
We examined the overlap of detected changepoints between preprints and published articles.
We found a decent number of tokens were related to the COVID-19 (Supplementary Table {@tbl:published_preprint_change_table}).
Plus, we also found that several shared tokens were terms related to experiments that involve animals or wet-lab work (Supplementary Table {@tbl:published_preprint_change_table}).

## Word-Lapse is an online resource that enables manual examination of any token 

![
A. The trajectory visualization of the token 'pandemic' through time.
It starts at the first mention of the token and progresses through each subsequent year.
Every datapoint shows the top five neighbors for the respective token. 
B. The usage frequency of the token 'pandemic' through time.
The x-axis shows the year, and the y-axis shows the frequency for each token.
C. A word cloud visualization for the top 25 neighbors for the token 'pandemic' each year.
This visualization highlights each neighbor from a particular year and allows for the comparison between two years.
Tokens in purple are shared within both years, while tokens in red or blue are unique to their respective year.
](images/Figure_4.png){#fig:website_walkthrough width="100%"}

We constructed an online application that allows users to examine how tokens change through time.
Tokens can be inputted as individual text or through MeSH IDs, Entrez Gene IDs, and Taxonomy IDs. 
Once a token is inputted, a user is introduced to a visualization that shows a token's trajectory through time (Figure {@fig:website_walkthrough}A).
Next, we show a frequency chart that depicts how often the particular token is used within each time period (Figure {@fig:website_walkthrough}B).
If a changepoint has been detected, this visualization will provide an indicator for such an event (Figure {@fig:website_walkthrough}B).
The last visualization we provide is a word cloud that shows 25 neighbors from each respective year (Figure {@fig:website_walkthrough}C), allowing for further examination of the differences between years.

