# Methods

## Biomedical Corpora Examined

### Pubtator Central

Pubtator Central is an open access resource that contains annotated PubMed abstracts and full text from PubMed Central [@doi:10.1093/nar/gkz389].
Each annotation used entity recognistion systems to label specific words and phrases to represent biomedical concepts.
More speficially, this resource used TaggerOne [@doi:10.1093/bioinformatics/btw343] to tag diseases, chemicals and cell line entities, GNormPlus [@doi:10.1155/2015/918710] to tag 
genes, SR4GN [@doi:10.1371/journal.pone.0038460] to tag species, and tmVar [@doi:10.1093/bioinformatics/btx541] to tag genetic mutations.
We downloaded this resource on March 09, 2022 and processed over 32 million different documents.
These documents date all the back to the pre-1800s; however, due to the low sample size, we only used documents published in the year 2000 to 2021.
Every extracted document was processed using spacy's en_core_web_sm model [@spacy2].
This model breaks down every paragraph into individual sentences.
For each sentnece we first replaced each tagged phrase with it's corresponding entity type and id that was previously identified.
Next, this model breaks each sentence down into individual tokens that are normlaized into their root from using a process called lemmatization.
After processing, we used all sentences to train multiple models that are designed to model words based on their context.

### Biomedical Preprints

BioRxiv [@doi:10.1101/833400v1] and MedRxiv [@doi:10.1126/science.aay2933] are repositories that contains preprints for the life science community.
MedRxiv is mainly focused on preprints that mention patient research, while BioRxiv is focused on general biology.
We downloaded a snapshot of both resources on March 4th, 2022, using their respective Amazon S3 bucket [@https://www.biorxiv.org/tdm; @https://www.medrxiv.org/tdm].
This snapshot contained 172,868 BioRxiv preprints and 37,517 MedRxiv preprints.
Unlike Pubtator Central, these preprints do not contain any annotations.
Therefore, we used TaggerOne [@doi:10.1093/bioinformatics/btw343] to tag every chemical and disease entity and GNormplus [@doi:10.1155/2015/918710] to tag every gene and species entity for all downloaded preprints.
Once tagged, we used spacy to break down each paragraph into sentences and replaced each tagged phrased with their corresponding entity type and id.
Lastly, we used spacy to break down each sentence into lemmatised tokens to be used for downstream analyses.


## Word Embeddings to capture word context

Word2vec [@arxiv:1301.3781] is an natural language processing model designed to model word context in the form of dense vectors.
This suite of models comes in two forms, a skipgram model and a continuous bags of words (CBOW) model.
The skipgram model models word context by having a neural network predicted the context given the word, while the CBOW model predicts the word given the context.
We used the CBOW model to capture this context for this project.
We split Pubmed Central dataset into abstracts and full text.
We trained ten different CBOW for vector size of 300, 10 epochs, minimum frequency cutoff of 10 and a window size of 16 for abstracts.
Full text provides a lot more sentences and we trained ten different word2vec models using the following parameters, vector size of 300, 10 epochs, minimum frequency cutoff of 10 and a window size of 16.

Despite the power of word2vec, these models generate their low dimensional constructs arbitrarily.
Based on this these models cannot be directly compared without an alignment step.
We used orthogonal procrustes [@doi:10.1007/BF02289451] to align every model to the first index of the most recent year.

## Detecting Semantic Change

Mention cosine similarity and how that metric works
Mention how you use cosine similarity to calculate intra year variation (within year) and inter year variation (across year)
Mention how you turn these values into a ratio metric and that you are adding the ratio metric with frequency
Mention how you use the CUSUM algorithm to detect the abnormal shifts.

## UMAP visualization

mention projection of words onto a 2D space

1. Pubtator Central
   1. breif description about the dataset
   2. talk about how it contains entities tagged
2. Word2vec Model
   1. training parameters
   2. Use 10 models for each year
   3. min cutoff is 10
3. Orthogonal Procrustes - to align models onto year 2021
   1. Allows for the models to be directly compared
4. Determining semantic change
	1. Cosine metric to determine difference between words
	2. Scaf ratio method to model temporal changes
	3. CUSUM to actually detect change throughout the years
5. Umap visualization
   1. Explain why aligned umap - preserves local and global structure
   2. mention parameters for aligned umap
